# üìã TODO LIST - PREPROCESSING VARIABLES ORDINALES ET CAT√âGORIELLES

## üéØ Objectif
Cr√©er une classe `OrdinalPreprocessor`et `CategoricalPreprocessor` avec des m√©thodes ind√©pendantes pour pr√©processer les 96 variables ordinales et 70 variables cat√©gorielles respectivement, en vue de pr√©dire **MathScore** (variable cible √† NE PAS modifier).

---

## üìä CONTEXTE DU DATASET

### Variables √† traiter :
- **96 variables ordinales** (31.2% du dataset)
  - 22 sur le contexte socio-√©conomique familial
  - 13 sur l'environnement de classe
  - 11 sur l'utilisation des TIC
  - 50 autres r√©parties sur 9 domaines

- **70 variables cat√©gorielles** (22.7% du dataset)
  - 28 variables g√©n√©rales (m√©tadonn√©es)
  - 42 variables th√©matiques r√©parties sur 10 domaines

### Variables encod√©es avec haute cardinalit√© :
- **STRATUM** : 1316 strates (urbain/rural, public/priv√©, r√©gions)
- **OCOD** : 620 codes de professions
- **CNT/CNTRYID** : 80 pays (information redondante)

---

## ‚úÖ TODO LIST D√âTAILL√âE

### üîµ PHASE 1 : ANALYSE EXPLORATOIRE (EDA) - Dans Jupyter Notebook
**Objectif** : Explorer les donn√©es r√©elles pour comprendre les distributions et guider le preprocessing

#### [V] 1.1 - Cr√©er notebook `preprocessing/01_eda_ordinal_categorical.ipynb`
- Charger √©chantillon de `data/X_train.csv` (10 000-50 000 lignes)
- Charger dictionnaires de r√©f√©rence du `data/Glossaire.xlsx`

#### [V] 1.2 - Identifier les variables ordinales et cat√©gorielles dans les donn√©es r√©elles
- Utiliser le classification_variable.xlsx pour classifier les variables
- Cr√©er listes: `ordinal_vars` (96 vars) et `categorical_vars` (70 vars)
- V√©rifier coh√©rence avec la structure r√©elle du dataset

#### [V] 1.3 - Analyser distributions des variables ordinales
- Cardinalit√© (nombre de valeurs uniques)
- % de valeurs manquantes par variable
- D√©tecter types d'√©chelles (Likert, fr√©quence, quantit√©)
- Identifier valeurs aberrantes ou codes sp√©ciaux (-99, 97, 98, 99)
- **Visualisations** : histogrammes, boxplots

#### [V] 1.4 - Analyser distributions des variables cat√©gorielles
- Cardinalit√© par variable (faible < 10, moyenne 10-50, haute > 50)
- % de valeurs manquantes
- Identifier cat√©gories rares (< 1% des observations)
- D√©s√©quilibre des classes (imbalance ratio)
- **Focus sp√©cial** : STRATUM (1316), OCOD (620), CNT (80)
- **Visualisations** : barplots, treemaps pour haute cardinalit√©

#### [V] 1.5 - D√©tecter variables redondantes / corr√©l√©es
- Calculer corr√©lations Spearman pour paires de variables ordinales
- Calculer Cram√©r's V pour paires de variables cat√©gorielles
- V√©rifier redondance CNT vs CNTRYID
- **Output** : Liste de variables √† supprimer

#### [V] 1.6 - Analyser patterns de valeurs manquantes
- Matrice de corr√©lation des valeurs manquantes
- Identifier si missing est informatif (MCAR, MAR, MNAR)
- D√©cider strat√©gie d'imputation par variable

#### [V] 1.7 - Documenter conclusions EDA
- Cr√©er rapport markdown avec d√©cisions de preprocessing
- Lister variables √† supprimer, √† regrouper, √† encoder
- D√©finir strat√©gies d'imputation par type de variable
- **Output** : `preprocessing/eda_conclusions.md`

#### [V] 1.8 - Analyser les colonnes d'apr√®s leurs noms et d√©duire ce qu'il faut supprimer / fusionner
- **Output** : `preprocessing/analysis/categorical_variables`, `preprocessing/analysis/ordinal_variables`

#### [V] 1.9 - Analyser des papiers de recherche sur ce sujet, en d√©duire les m√©thodes recommand√©es

#### [V] 1.10 - Faire une synth√®se des recommandations et mettre √† jour cette to do list
- Synth√®se √† partir de `preprocessing/analysis/categorial_variables/RESUME_EXECUTIF_Analyse_Categorielles.md`,
`preprocessing/analysis/ordinal_variables/RESUME_EXECUTIF_Analyse_Ordinales.md`,
`preprocessing/analysis/analysis_from_pappers.md`et `preprocessing/01_eda_ordinal_categorical.ipynb`
- **Output** : `preprocessing/analysis/conclusion_eda.md`
- Mettre √† jour la suite de cette To Do List.

---

### üü° PHASE 2 : CR√âATION DES CLASSES DE PREPROCESSING
**Objectif** : Impl√©menter le sc√©nario CONSERVATEUR (Phases 1-2) avec 2 classes OOP

#### [] 2.1 - Cr√©er classe `OrdinalPreprocessor` dans `preprocessing/classes/ordinal_preprocessor.py`
**Objectif** : Classe pour g√©rer toutes les transformations des variables ordinales

**M√©thodes √† impl√©menter** :

```python
class OrdinalPreprocessor:
    def __init__(self):
        self.ordinal_vars = []  # Liste variables ordinales
        self.variables_to_drop = []
        self.composite_scores = {}
        self.encoders = {}
        self.scaler = None

    # Phase 1 : Nettoyage
    def drop_redundant_variables(self, df: pd.DataFrame) -> pd.DataFrame:
        """Supprimer 5 variables ordinales redondantes"""
        # ST005, ST007, ST253, ST255, ST097

    # Phase 2 : Scores composites
    def create_composite_scores(self, df: pd.DataFrame) -> pd.DataFrame:
        """Cr√©er scores composites pour variables mesurant m√™me construit"""
        # Score_Support_Parental = moyenne(PA003, ST300)
        # Score_Support_Enseignant = moyenne(ST100, ST270)

    # Phase 3 : Imputation
    def impute_knn(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                   df_test: pd.DataFrame, k: int = 5) -> tuple:
        """Imputer valeurs manquantes avec KNN (fit sur train)"""

    # Phase 4 : Traitement outliers
    def winsorize_outliers(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                          df_test: pd.DataFrame, limits: list = [0.01, 0.01]) -> tuple:
        """Winsorization au 99√®me percentile"""

    # Phase 5 : Encodage
    def encode_ordinal_variables(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                                df_test: pd.DataFrame) -> tuple:
        """Encoder variables ordinales en pr√©servant l'ordre (fit sur train)"""

    # Phase 6 : Standardisation
    def standardize_variables(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                             df_test: pd.DataFrame) -> tuple:
        """Standardiser variables ordinales (fit sur train)"""

    # Utils
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pipeline complet pour train"""

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Appliquer transformations sur val/test"""

    def save(self, filepath: str):
        """Sauvegarder preprocessor"""

    @staticmethod
    def load(filepath: str):
        """Charger preprocessor sauvegard√©"""
```

**Sous-t√¢ches** :
- Impl√©menter les 9 m√©thodes ci-dessus
- Documenter chaque m√©thode avec docstrings
- G√©rer les valeurs manquantes lors des scores composites
- Stocker tous les transformers (encoders, scaler) comme attributs
- **Gain** : -7 variables ordinales (-5 suppressions + -2 par scores composites)

#### [] 2.2 - Cr√©er classe `CategoricalPreprocessor` dans `preprocessing/classes/categorical_preprocessor.py`
**Objectif** : Classe pour g√©rer toutes les transformations des variables cat√©gorielles

**M√©thodes √† impl√©menter** :

```python
class CategoricalPreprocessor:
    def __init__(self):
        self.categorical_vars = []  # Liste variables cat√©gorielles
        self.variables_to_drop = []
        self.isco_mapping = {}
        self.rare_categories_mapping = {}
        self.binary_encoders = {}
        self.onehot_encoder = None
        self.frequency_encoders = {}

    # Phase 1 : Nettoyage
    def drop_metadata_variables(self, df: pd.DataFrame) -> pd.DataFrame:
        """Supprimer 10 m√©tadonn√©es cat√©gorielles (risque Z√âRO)"""
        # Option_CT, Option_FL, Option_ICTQ, Option_PQ, Option_TQ,
        # Option_UH, Option_WBQ, CYC, NatCen, SUBNATIO

    def drop_redundant_variables(self, df: pd.DataFrame) -> pd.DataFrame:
        """Supprimer 7 redondances cat√©gorielles"""
        # LANGTEST_PAQ, LANGTEST_QQQ, ST003D03T, ST001D01T,
        # PA008, PA162, OCOD3

    # Phase 2 : Regroupement ISCO (CRITIQUE)
    def group_isco_codes(self, df: pd.DataFrame) -> pd.DataFrame:
        """Regrouper codes ISCO (620 ‚Üí 10 cat√©gories)"""
        # OCOD1 ‚Üí OCOD1_grouped (10 cat√©gories)
        # OCOD2 ‚Üí OCOD2_grouped (10 cat√©gories)
        # Impact : -1240 features potentielles

    # Phase 3 : Imputation
    def impute_mode(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                    df_test: pd.DataFrame) -> tuple:
        """Imputer avec mode (calcul√© sur train)"""

    # Phase 4 : Cat√©gories rares
    def group_rare_categories(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                              df_test: pd.DataFrame, threshold: float = 0.01) -> tuple:
        """Regrouper cat√©gories < 1% en 'Other' (fit sur train)"""

    # Phase 5 : Encodage
    def encode_binary_variables(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                                df_test: pd.DataFrame) -> tuple:
        """Encoder variables binaires en 0/1 (fit sur train)"""

    def onehot_encode_low_cardinality(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                                      df_test: pd.DataFrame, max_categories: int = 10) -> tuple:
        """One-Hot encoding pour cardinalit√© ‚â§10 (fit sur train)"""

    def frequency_encode_high_cardinality(self, df_train: pd.DataFrame, df_val: pd.DataFrame,
                                         df_test: pd.DataFrame) -> tuple:
        """Frequency encoding pour cardinalit√© >10 (fit sur train)"""

    # Utils
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pipeline complet pour train"""

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Appliquer transformations sur val/test"""

    def save(self, filepath: str):
        """Sauvegarder preprocessor"""

    @staticmethod
    def load(filepath: str):
        """Charger preprocessor sauvegard√©"""
```

**Sous-t√¢ches** :
- Impl√©menter les 12 m√©thodes ci-dessus
- Documenter chaque m√©thode avec docstrings
- Impl√©menter fonction `regroup_isco_codes()` pour extraire 1er chiffre
- Stocker tous les encoders/mappings comme attributs
- **Gain** : -17 variables cat√©gorielles (-10 m√©tadonn√©es + -7 redondances)

#### [] 2.3 - Cr√©er fonctions utilitaires `preprocessing/utils/preprocessing_utils.py`
**Objectif** : Fonctions auxiliaires pour orchestrer les 2 preprocessors

**Fonctions √† impl√©menter** :

```python
def remove_high_missing_vars(df: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:
    """Supprimer variables avec >50% missing"""
    missing_pct = df.isnull().mean()
    high_missing = missing_pct[missing_pct > threshold].index.tolist()
    print(f"Suppression de {len(high_missing)} variables avec >{threshold*100}% missing")
    return df.drop(columns=high_missing)

def split_train_val_test(df: pd.DataFrame, target: str = 'MathScore',
                        test_size: float = 0.2, val_size: float = 0.2,
                        random_state: int = 42) -> tuple:
    """Split stratifi√© 60/20/20 sur bins de target"""
    # Cr√©er bins pour stratification
    # Retourner X_train, X_val, X_test, y_train, y_val, y_test

def validate_preprocessing(df_before: pd.DataFrame, df_after: pd.DataFrame,
                          target: str = 'MathScore') -> dict:
    """Valider preprocessing (no missing, dtypes, target unchanged)"""
    # V√©rifier 0 NaN
    # V√©rifier target identique
    # Retourner rapport validation

def generate_preprocessing_report(df_before: pd.DataFrame, df_after: pd.DataFrame,
                                 ordinal_prep, categorical_prep) -> dict:
    """G√©n√©rer rapport preprocessing complet (markdown + JSON)"""
    # Variables supprim√©es
    # Variables cr√©√©es
    # Statistiques imputation
    # Retourner dict avec toutes les m√©tadonn√©es
```

**Sous-t√¢ches** :
- Impl√©menter les 4 fonctions ci-dessus
- Documenter avec docstrings
- G√©rer stratification sur bins de MathScore
- **Output** : Module utils avec fonctions helper

#### [] 2.4 - Cr√©er tests unitaires `preprocessing/tests/test_preprocessors.py`
**Objectif** : Tester chaque m√©thode des classes

**Sous-t√¢ches** :
- Tester OrdinalPreprocessor (drop, composite, encode, etc.)
- Tester CategoricalPreprocessor (drop, ISCO, encode, etc.)
- Tester PISAPreprocessor (pipeline complet)
- Tester que MathScore n'est jamais modifi√©
- Tester absence de data leakage (fit/transform s√©par√©s)
- **Output** : Suite de tests avec pytest

---

### üü¢ PHASE 3 : FEATURE SELECTION ET VALIDATION

#### [] 6.1 - Impl√©menter feature selection hybride `preprocessing/scripts/feature_selection.py`
**Objectif** : S√©lectionner ~20-35 features optimales (recommandation litt√©rature)

**Sous-t√¢ches** :
- Calculer Mutual Information sur train set
  ```python
  from sklearn.feature_selection import mutual_info_regression
  mi_scores = mutual_info_regression(X_train, y_train)
  ```
- Impl√©menter Recursive Feature Elimination avec RandomForest
  ```python
  from sklearn.feature_selection import RFE
  rfe = RFE(estimator=rf, n_features_to_select=30)
  ```
- Cr√©er intersection des features s√©lectionn√©es par les 2 m√©thodes
- **Output** : Liste de features s√©lectionn√©es + scores d'importance

#### [] 3.2 - Cr√©er notebook de validation `preprocessing/02_validation_preprocessing.ipynb`
**Objectif** : Valider le preprocessing complet et analyser r√©sultats

**Pipeline d'ex√©cution** :
```python
from classes.ordinal_preprocessor import OrdinalPreprocessor
from classes.categorical_preprocessor import CategoricalPreprocessor
from utils.preprocessing_utils import *

# 1. Charger donn√©es
df = pd.read_csv('data/X_train.csv')

# 2. Remove high missing
df = remove_high_missing_vars(df, threshold=0.5)

# 3. Appliquer nettoyage (avant split)
ordinal_prep = OrdinalPreprocessor()
categorical_prep = CategoricalPreprocessor()

df = ordinal_prep.drop_redundant_variables(df)
df = categorical_prep.drop_metadata_variables(df)
df = categorical_prep.drop_redundant_variables(df)
df = categorical_prep.group_isco_codes(df)
df = ordinal_prep.create_composite_scores(df)

# 4. Split train/val/test
X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(df)

# 5. Appliquer transformations (fit sur train)
X_train, X_val, X_test = ordinal_prep.impute_knn(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.impute_mode(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.winsorize_outliers(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.group_rare_categories(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.encode_ordinal_variables(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.encode_binary_variables(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.onehot_encode_low_cardinality(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.frequency_encode_high_cardinality(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.standardize_variables(X_train, X_val, X_test)

# 6. Validation
validation_report = validate_preprocessing(df, X_train, target='MathScore')
preprocessing_report = generate_preprocessing_report(df, X_train, ordinal_prep, categorical_prep)
```

**Sous-t√¢ches** :
- Ex√©cuter pipeline complet ci-dessus
- Valider absence NaN apr√®s preprocessing
- V√©rifier MathScore non modifi√©
- Visualiser distributions avant/apr√®s
- Comparer statistiques descriptives
- **Output** : Notebook validation + rapport

---

### üü£ PHASE 4 : UTILISATION ET EXPORT

#### [] 4.1 - Cr√©er script d'utilisation `preprocessing/run_preprocessing.py`
**Objectif** : Script principal pour lancer le preprocessing complet

**Sous-t√¢ches** :
```python
from classes.ordinal_preprocessor import OrdinalPreprocessor
from classes.categorical_preprocessor import CategoricalPreprocessor
from utils.preprocessing_utils import *
import pandas as pd

# Charger donn√©es
df = pd.read_csv('data/X_train.csv')
df_before = df.copy()

# 1. Remove high missing
df = remove_high_missing_vars(df, threshold=0.5)

# 2. Nettoyage (avant split)
ordinal_prep = OrdinalPreprocessor()
categorical_prep = CategoricalPreprocessor()

df = ordinal_prep.drop_redundant_variables(df)
df = categorical_prep.drop_metadata_variables(df)
df = categorical_prep.drop_redundant_variables(df)
df = categorical_prep.group_isco_codes(df)
df = ordinal_prep.create_composite_scores(df)

# 3. Split
X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(df)

# 4. Transformations (fit sur train)
X_train, X_val, X_test = ordinal_prep.impute_knn(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.impute_mode(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.winsorize_outliers(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.group_rare_categories(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.encode_ordinal_variables(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.encode_binary_variables(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.onehot_encode_low_cardinality(X_train, X_val, X_test)
X_train, X_val, X_test = categorical_prep.frequency_encode_high_cardinality(X_train, X_val, X_test)
X_train, X_val, X_test = ordinal_prep.standardize_variables(X_train, X_val, X_test)

# 5. Sauvegarder preprocessors
ordinal_prep.save('models/ordinal_preprocessor.pkl')
categorical_prep.save('models/categorical_preprocessor.pkl')

# 6. Sauvegarder datasets
X_train.to_csv('data/processed/X_train_preprocessed.csv', index=False)
X_val.to_csv('data/processed/X_val_preprocessed.csv', index=False)
X_test.to_csv('data/processed/X_test_preprocessed.csv', index=False)
y_train.to_csv('data/processed/y_train.csv', index=False)
y_val.to_csv('data/processed/y_val.csv', index=False)
y_test.to_csv('data/processed/y_test.csv', index=False)

# 7. G√©n√©rer rapport
report = generate_preprocessing_report(df_before, X_train, ordinal_prep, categorical_prep)
```

#### [] 4.2 - Cr√©er notebook d√©mo `preprocessing/03_demo_preprocessing.ipynb`
**Objectif** : D√©monstration compl√®te du preprocessing

**Sous-t√¢ches** :
- Charger donn√©es brutes
- Montrer √©tape par √©tape chaque transformation
- Visualiser impact de chaque √©tape
- Afficher statistiques avant/apr√®s
- Sauvegarder r√©sultats finaux
- **Output** : Notebook d√©mo comment√©


---

## üéØ INSIGHTS CL√âS DE L'ANALYSE EDA (Synth√®se Phase 1.10)

### üí° D√©couvertes Majeures

1. **Explosion de Dimensionnalit√© √âvit√©e**
   - **AVANT** : ~2093 features apr√®s one-hot encoding
   - **APR√àS** : ~224 features avec sc√©nario conservateur
   - **GAIN** : -89% de features (-1869 features)
   - **Impact principal** : Regroupement ISCO (620 ‚Üí 10 cat√©gories) = -97% features cat√©gorielles

2. **M√©tadonn√©es Non Pr√©dictives**
   - 40% des variables cat√©gorielles sont des m√©tadonn√©es administratives
   - Suppression de 12 variables avec risque Z√âRO
   - Variables : Options questionnaires, identifiants admin, effort post-test

3. **Redondances Structurelles Identifi√©es**
   - 7 variables ordinales redondantes (doublons ISCED, ressources num√©riques)
   - 7 variables cat√©gorielles redondantes (langues, dates, professions)
   - Opportunit√© de cr√©er 2 scores composites (support parental, support enseignant)

4. **Sc√©nario CONSERVATEUR Recommand√©**
   - Phases 1-2 : R√©duction 166 ‚Üí 138 variables (-16.9%)
   - Risque MINIMAL valid√© par analyses multiples
   - Timeline : IMM√âDIAT (cette semaine)
   - Validation empirique Phase 3 (COVID, TIC) : Semaine prochaine

5. **Variables Critiques √† Conserver** (Valid√©es litt√©rature + analyses)
   - ESCS, HISEI, ICTRES : Top importance syst√©matique
   - Gender, IMMIG, GRADE : Sociod√©mographiques essentiels
   - IC184, METASPAM, COMPETE : Sp√©cifiques math√©matiques

6. **Pipeline Valid√© par Litt√©rature**
   - KNN imputation (k=5) pour continues/ordinales
   - Mode imputation pour cat√©gorielles
   - StandardScaler apr√®s encoding
   - Feature selection hybride (RFE + MI) ‚Üí ~20-35 features
   - Cross-validation 5-fold pour validation

### üìä Ordre des Transformations (CRITIQUE pour √©viter Data Leakage)

**S√âQUENCE STRICTE √Ä RESPECTER** :
1. Remove PV*/WLE* (avant tout)
2. Remove high missing >50%
3. Clean variables (Phases 1-2)
4. **SPLIT TRAIN/VAL/TEST** ‚Üê Point critique
5. Imputation (fit train, transform val/test)
6. Outliers treatment (fit train, transform val/test)
7. Encoding (fit train, transform val/test)
8. Standardization (fit train, transform val/test)
9. Feature selection (train only)

### üéì Recommandations Issues de 4 √âtudes Scientifiques
- **Imputation** : KNN (k=5) > Simple mean/median
- **Encoding haute cardinalit√©** : Frequency > Target (√©vite leakage)
- **Standardisation** : Obligatoire pour convergence mod√®les
- **Feature selection** : RFE + MI > univari√© seul
- **Validation** : Stratified 5-fold CV
- **Split** : 60/20/20 avec stratification sur target bins

### ‚ö° Quick Wins Identifi√©s
1. **Gain imm√©diat** : Supprimer 22 variables m√©tadonn√©es/redondances (-13.3% variables)
   - 5 ordinales (ST005, ST007, ST253, ST255, ST097)
   - 10 m√©tadonn√©es cat√©gorielles (Options + identifiants admin)
   - 7 redondances cat√©gorielles (langues, dates, professions)
2. **Gain massif** : Regrouper ISCO (-1860 features potentielles ‚Üí -97% features cat√©gorielles)
3. **Gain consolidation** : 2 scores composites (-2 variables ordinales)
4. **Total Phase 1-2** : 166 ‚Üí 142 variables (-14.5%), ~2093 ‚Üí ~224 features (-89%)
5. **Note Hackathon** : PV*/WLE* gard√©s pour performance maximale

---

## ‚ö†Ô∏è POINTS D'ATTENTION CRITIQUES

### üö® Data Leakage
- **Target encoding** : OBLIGATOIRE d'utiliser cross-validation
- **Imputation** : Calculer statistiques UNIQUEMENT sur train set
- **Scaling** : Fit sur train, transform sur test

### üö® Gestion de MathScore (Cible)
- **NE JAMAIS** modifier, imputer, ou encoder MathScore
- V√©rifier apr√®s chaque transformation avec `check_target_variable_unchanged()`
- Exclure MathScore de toutes les transformations

### üö® Haute Cardinalit√©
- STRATUM (1316) et OCOD (620) : **R√âDUCTION OBLIGATOIRE**
- Ne JAMAIS faire de one-hot sur ces variables
- Privil√©gier feature engineering intelligent

### üö® Variables Redondantes
- CNT vs CNTRYID : supprimer l'un des deux
- V√©rifier corr√©lations avant encodage

### üö® Pr√©servation de l'Information Ordinale
- Ne JAMAIS one-hot des variables ordinales
- Utiliser OrdinalEncoder avec mapping explicite
- Documenter l'ordre des modalit√©s

---

## üìä LIVRABLES ATTENDUS

1. **Classe Python** : `OrdinalCategoricalPreprocessor` avec toutes les m√©thodes
2. **Notebook d'exemples** : D√©monstration de chaque m√©thode
3. **Dataset preprocess√©** : Fichier final pr√™t pour mod√©lisation
4. **Documentation** : Rapport de preprocessing d√©taill√©
5. **Encoders sauvegard√©s** : Fichiers .pkl pour r√©utilisation

---

## üéì BONNES PRATIQUES √Ä RESPECTER

‚úÖ **Programmation Orient√©e Objet** : Cr√©er des classes si c'est pertinent.
‚úÖ **Noms de fonctions explicites** : `encode_ordinal_variables` pas `encode_vars`
‚úÖ **Docstrings compl√®tes** : Param√®tres, returns, exemples
‚úÖ **Type hints** : `def func(df: pd.DataFrame) -> pd.DataFrame`
‚úÖ **Logging** : Logger chaque transformation importante
‚úÖ **Tra√ßabilit√©** : Conserver metadata de chaque transformation
‚úÖ **Tests** : Valider sur √©chantillon avant full dataset
‚úÖ **Modularit√©** : Chaque fonction fait UNE chose
‚úÖ **R√©utilisabilit√©** : Code applicable √† de nouvelles donn√©es

---

## üìù NOTES FINALES

- Cette TODO list est **exhaustive mais flexible** : adapter selon les donn√©es r√©elles
- Certaines m√©thodes peuvent √™tre optionnelles selon les analyses de Phase 1
- Prioriser la **vitesse** sur la qualit√© : seulement quelques heures pour cet exercice!
- **Documenter** toutes les d√©cisions prises et les justifier