# ğŸ¯ CONCLUSION - Analyse Exploratoire des DonnÃ©es PISA

## SynthÃ¨se GÃ©nÃ©rale

Cette analyse exploratoire complÃ¨te des donnÃ©es PISA a permis d'identifier les opportunitÃ©s majeures d'optimisation du preprocessing pour la prÃ©diction du score en mathÃ©matiques (MathScore). L'analyse s'est concentrÃ©e sur trois axes complÃ©mentaires : les variables ordinales, les variables catÃ©gorielles, et les recommandations issues de la littÃ©rature scientifique.

---

## ğŸ“Š Vue d'Ensemble des DonnÃ©es

### Ã‰tat Initial du Dataset
- **96 variables ordinales** rÃ©parties dans 13 domaines thÃ©matiques
- **70 variables catÃ©gorielles** avec forte concentration dans le domaine General (40%)
- **DÃ©fi majeur** : Explosion potentielle de dimensionnalitÃ© (~2093 features aprÃ¨s encoding)
- **ProblÃ©matique critique** : Codes ISCO haute cardinalitÃ© (620 codes Ã— 3 variables)

### Distribution des Variables
- **Domaines principaux ordinaux** :
  - Family Background & Socioeconomic Status (22 variables)
  - Classroom Environment & Teaching Practices (13 variables)
  - ICT Use & Digital Competence (11 variables)

- **Domaines principaux catÃ©goriels** :
  - General (28 variables - 40% du total)
  - MÃ©tadonnÃ©es administratives (significant portion)

---

## ğŸ”¥ DÃ‰COUVERTES CRITIQUES

### 1. Explosion de DimensionnalitÃ© - Variables CatÃ©gorielles

**Impact AVANT nettoyage** :
```
OCOD1 (620) + OCOD2 (620) + OCOD3 (620) + Autres (50 vars)
= ~1910 features aprÃ¨s one-hot encoding
```

**Impact APRÃˆS optimisation** :
```
OCOD1_grouped (10) + OCOD2_grouped (10) + Autres (30 vars)
= ~50 features aprÃ¨s encoding
```

**ğŸ‰ GAIN : -97% de features catÃ©gorielles** (1910 â†’ 50)

### 2. Redondances Structurelles

**Variables ordinales** :
- Redondances Ã©ducation parents : ST005/ST006 (mÃ¨re) et ST007/ST008 (pÃ¨re) - on garde les codes ISCED numÃ©riques
- Redondances ressources numÃ©riques : ST253/ST254 et ST255/ST256 - on supprime un des deux
- Redondances perturbations classe : ST097/ST273 - on supprime un des deux
- Variables mesurant le mÃªme construit (support enseignant, support parental)

**Variables catÃ©gorielles** :
- 40% des variables sont des mÃ©tadonnÃ©es administratives non prÃ©dictives
- Multiples variables d'options de questionnaires (7 variables)
- Identifiants administratifs sans valeur prÃ©dictive (3 variables)

### 3. Risque de Data Leakage

**Variables Ã  EXCLURE ABSOLUMENT** :
- Toutes les PValues (PV1MATH Ã  PV10MATH)
- Variables WLE (Weighted Likelihood Estimates)
- Variables d'effort post-test (EFFORT1, EFFORT2)

**Justification** : Ces variables reprÃ©sentent dÃ©jÃ  la cible ou sont gÃ©nÃ©rÃ©es aprÃ¨s le test, crÃ©ant un risque de fuite d'information.

IMPORTANT: cette idÃ©e est rejetÃ©e dans le cadre de ce hackathon car on veut les meilleures performances possibles sachant qu'on aura un X_test qui a les mÃªmes donnÃ©es que le X_train. 

---

## âš¡ PLAN D'ACTION RECOMMANDÃ‰

### ğŸ”´ PHASE 1 : Suppressions Sans Risque (EXÃ‰CUTION IMMÃ‰DIATE)

#### Variables Ordinales (-5 variables)
```python
variables_ordinales_a_supprimer = [
    'ST005',   # Education mÃ¨re (description) - redondant avec ST006 (code ISCED)
    'ST007',   # Education pÃ¨re (description) - redondant avec ST008 (code ISCED)
    'ST253',   # Redondant avec ST254
    'ST255',   # Redondant avec ST256
    'ST097'    # Redondant avec ST273
]
# Gain net: -5 variables ordinales
# Risque: MINIMAL
# Note: On garde ST006 et ST008 (codes ISCED numÃ©riques ordinaux)
```

#### Variables CatÃ©gorielles - MÃ©tadonnÃ©es (-10 variables)
```python
metadonnees_a_supprimer = [
    # Options questionnaires (7)
    'Option_CT', 'Option_FL', 'Option_ICTQ', 'Option_PQ',
    'Option_TQ', 'Option_UH', 'Option_WBQ',

    # Identifiants administratifs (3)
    'CYC', 'NatCen', 'SUBNATIO'
]
# Gain net: -10 variables catÃ©gorielles
# Risque: ZÃ‰RO
# Note: EFFORT1/EFFORT2 retirÃ©s car pas de data leakage en hackathon
```

#### Variables CatÃ©gorielles - Redondances (-7 variables)
```python
redondances_categorielles_a_supprimer = [
    'LANGTEST_PAQ',      # Redondant avec LANGTEST_COG
    'LANGTEST_QQQ',      # Redondant avec LANGTEST_COG
    'ST003D03T',         # Birth Year = redondant avec AGE
    'ST001D01T',         # Grade = redondant avec GRADE
    'PA008',             # Doublon (une des copies de PA008)
    'PA162',             # Lecture parent (garder ST168)
    'OCOD3',             # Profession aspirÃ©e (faible valeur + haute cardinalitÃ©)
]
# Gain net: -7 variables catÃ©gorielles
# Risque: MINIMAL
```

**ğŸ“ˆ GAIN PHASE 1 : -22 variables** (-5 ordinales + -10 mÃ©tadonnÃ©es + -7 redondances catÃ©gorielles)

---

### ğŸŸ  PHASE 2 : Consolidations et Fusions (PRIORITÃ‰ HAUTE)

#### Scores Composites - Variables Ordinales
```python
# Fusionner variables mesurant mÃªme construit
fusions_ordinales = {
    'Score_Support_Parental': ['PA003', 'ST300'],
    'Score_Support_Enseignant': ['ST100', 'ST270']
}
# MÃ©thode : Moyenne ou PCA sur composantes
# Gain net: -2 variables ordinales
```

#### Regroupement ISCO - Variables CatÃ©gorielles (CRITIQUE)
```python
def regroup_isco_codes(isco_code):
    """
    Regrouper codes ISCO-08 (620) en 10 grandes catÃ©gories

    CatÃ©gories ISCO niveau 1:
    1: Managers
    2: Professionals
    3: Technicians and associate professionals
    4: Clerical support workers
    5: Service and sales workers
    6: Skilled agricultural, forestry and fishery workers
    7: Craft and related trades workers
    8: Plant and machine operators, and assemblers
    9: Elementary occupations
    0: Armed forces occupations
    """
    if pd.isna(isco_code):
        return np.nan

    # Prendre le 1er chiffre du code (niveau 1 ISCO)
    return int(str(int(isco_code))[0])

# Appliquer le regroupement
df['OCOD1_grouped'] = df['OCOD1'].apply(regroup_isco_codes)
df['OCOD2_grouped'] = df['OCOD2'].apply(regroup_isco_codes)

# Supprimer les codes originaux
df = df.drop(columns=['OCOD1', 'OCOD2'])

# Impact:
# - CardinalitÃ©: 620 â†’ 10 par variable
# - Features aprÃ¨s encoding: 1240 â†’ 20
# - RÃ©duction: -98% de features ISCO
```

**ğŸ“ˆ GAIN PHASE 2 : -2 variables ordinales + Impact massif sur features catÃ©gorielles**

---

### ğŸŸ¡ PHASE 3 : Variables Ã  Ã‰valuer Empiriquement

#### Variables COVID (Ã€ DÃ‰CIDER selon objectif)

**Option A - Score Composite COVID**
```python
# Si pertinent pour capturer l'effet COVID
variables_covid = ['ST348', 'ST351', 'ST352', 'ST353']  # Ordinales
variables_covid_cat = ['ST347', 'ST349', 'ST350']        # CatÃ©gorielles

# CrÃ©er score composite
score_covid = moyenne_ou_pca(variables_covid + variables_covid_cat)
# Gain: -6 variables
```

**Option B - Suppression COVID**
```python
# Si COVID n'impacte pas significativement MathScore
# (Ã  valider par test de corrÃ©lation)
supprimer(variables_covid + variables_covid_cat)
# Gain: -7 variables
```

**CritÃ¨re de dÃ©cision** : Tester corrÃ©lation avec MathScore et importance dans modÃ¨les baseline

#### Consolidation TIC (Ã€ VALIDER)
```python
# Variables IC170-176 (usage TIC par domaine)
# GARDER ABSOLUMENT : IC184 (usage TIC mathÃ©matiques)
# Ã€ Ã©valuer : Autres variables TIC potentiellement redondantes
# Gain potentiel: -4 variables ordinales
```

---

## ğŸ“Š SCÃ‰NARIOS DE RÃ‰DUCTION

### ScÃ©nario CONSERVATEUR â­ (RECOMMANDÃ‰)

**Actions** : Phases 1 + 2

**Impact Variables** :
- Ordinales : 96 â†’ **89 variables** (-7 variables : -5 suppressions + -2 par scores composites)
- CatÃ©gorielles : 70 â†’ **53 variables** (-17 variables : -10 mÃ©tadonnÃ©es + -7 redondances)
- **Total : 166 â†’ 142 variables (-14.5%)**

**Impact Features (aprÃ¨s encoding)** :
- Avant : ~2093 features (81 numÃ©riques + 96 ordinales + 1910 catÃ©gorielles + 6 groupement)
- AprÃ¨s : ~224 features (81 numÃ©riques + 87 ordinales + 50 catÃ©gorielles + 6 groupement)
- **GAIN GLOBAL : -89% de features (-1869 features)**

**Risque** : MINIMAL
**Timeline** : IMMÃ‰DIAT

---

### ScÃ©nario AGRESSIF

**Actions** : Phases 1 + 2 + 3

**Impact Variables** :
- Ordinales : 96 â†’ **74-78 variables** (-18 Ã  -22 variables)
- CatÃ©gorielles : 70 â†’ **44-48 variables** (-22 Ã  -26 variables)
- **Total : 166 â†’ 118-126 variables (-24 Ã  -29%)**

**Impact Features** : ~2093 â†’ ~200 features (-90%)

**Risque** : MOYEN (perte information granulaire TIC et COVID)
**Timeline** : AprÃ¨s validation empirique

---

## ğŸ¯ RECOMMANDATIONS PREPROCESSING (BasÃ©es sur la littÃ©rature)

### 1. Gestion des Valeurs Manquantes

**StratÃ©gie recommandÃ©e** :
```python
# 1. Ã‰liminer variables avec >50% missing
high_missing_vars = [var for var in df.columns
                     if df[var].isna().mean() > 0.5]
df = df.drop(columns=high_missing_vars)

# 2. Imputation KNN (k=5) pour continues et ordinales
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)
df[continuous_vars] = imputer.fit_transform(df[continuous_vars])
df[ordinal_vars] = imputer.fit_transform(df[ordinal_vars])

# 3. Mode pour catÃ©gorielles
for var in categorical_vars:
    df[var].fillna(df[var].mode()[0], inplace=True)
```

**Justification** :
- KNN prÃ©serve mieux les relations entre variables que l'imputation simple
- Variables avec >50% missing n'apportent pas d'information fiable
- RecommandÃ© par 2 Ã©tudes scientifiques analysÃ©es

### 2. Protection Contre le Data Leakage

**Note Hackathon** : En contexte hackathon oÃ¹ X_test a les mÃªmes features que X_train, on GARDE les PV*/WLE* pour maximiser la performance. En production, il faudrait les exclure.

**En production classique (EXCLURE ABSOLUMENT)** :
```python
# Variables gÃ©nÃ©rÃ©es aprÃ¨s le test ou reprÃ©sentant la cible
leakage_vars = [
    # PValues - imputation multiple de la cible
    'PV1MATH', 'PV2MATH', ..., 'PV10MATH',
    # WLE - Weighted Likelihood Estimates
    'WLE_*',
    # Effort post-test (si non pertinent)
    # 'EFFORT1', 'EFFORT2'  # GardÃ©s en hackathon
]
# df = df.drop(columns=leakage_vars)  # CommentÃ© pour hackathon
```

### 3. Encodage et Normalisation

```python
# 1. SPLIT TRAIN/VALIDATION/TEST (60/20/20)
# IMPORTANT : Faire AVANT tout preprocessing pour Ã©viter leakage

from sklearn.model_selection import train_test_split

X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.4, random_state=42, stratify=bins_of_y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=bins_of_y_temp
)

# 2. ENCODAGE (aprÃ¨s split)
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

# One-hot pour catÃ©gorielles nominales
ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_train_cat = ohe.fit_transform(X_train[categorical_vars])
X_val_cat = ohe.transform(X_val[categorical_vars])
X_test_cat = ohe.transform(X_test[categorical_vars])

# Ordinal pour variables ordinales
oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
X_train_ord = oe.fit_transform(X_train[ordinal_vars])
X_val_ord = oe.transform(X_val[ordinal_vars])
X_test_ord = oe.transform(X_test[ordinal_vars])

# 3. STANDARDISATION (aprÃ¨s split et encoding)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_num = scaler.fit_transform(X_train[numeric_vars])
X_val_num = scaler.transform(X_val[numeric_vars])
X_test_num = scaler.transform(X_test[numeric_vars])
```

**Pourquoi cette sÃ©quence** :
- Split AVANT preprocessing pour Ã©viter data leakage
- Fit sur train, transform sur val/test pour Ã©viter information leakage
- StandardScaler amÃ©liore convergence des modÃ¨les et interprÃ©tabilitÃ©

### 4. Traitement des Outliers

```python
# Winsorization au 99Ã¨me percentile
from scipy.stats.mstats import winsorize

for var in continuous_vars:
    X_train[var] = winsorize(X_train[var], limits=[0.01, 0.01])
    # Note: Appliquer les mÃªmes bornes sur val/test basÃ©es sur train
```

### 5. SÃ©lection de Features

**Approche hybride recommandÃ©e** :
```python
from sklearn.feature_selection import RFE, mutual_info_regression
from sklearn.ensemble import RandomForestRegressor

# 1. Mutual Information (capture dÃ©pendances non-linÃ©aires)
mi_scores = mutual_info_regression(X_train, y_train)
mi_features = X_train.columns[mi_scores > threshold]

# 2. Recursive Feature Elimination
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rfe = RFE(estimator=rf, n_features_to_select=30)
rfe.fit(X_train, y_train)
rfe_features = X_train.columns[rfe.support_]

# 3. Intersection des deux mÃ©thodes
selected_features = list(set(mi_features) & set(rfe_features))

# 4. AprÃ¨s modÃ©lisation : Permutation Importance + SHAP
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
# Analyser importance globale et locale
```

**Justification** :
- RFE Ã©limine itÃ©rativement les features peu importantes
- MI capture les dÃ©pendances non-linÃ©aires
- SHAP fournit interprÃ©tabilitÃ© locale et globale
- Objectif : Conserver ~20-35 features optimales

---

## ğŸ“‹ VARIABLES Ã€ CONSERVER ABSOLUMENT

### Variables Critiques (Ne JAMAIS Supprimer)

**ValidÃ©es par littÃ©rature ET analyses** :

1. **ESCS** (Economic, Social and Cultural Status) - SystÃ©matiquement top importance
2. **HISEI** (Highest parental occupational status) - SystÃ©matiquement top importance
3. **ICTRES** (ICT resources) - TrÃ¨s important pour tous domaines
4. **ST004D01T** (Gender) - SociodÃ©mographique clÃ© + Ã©quitÃ©
5. **IMMIG** (Immigration status) - Important pour fairness/equity
6. **GRADE** (Position in grade) - Capture redoublement (fort impact MathScore)
7. **ADMINMODE** (Computer vs Paper) - Mode peut influencer performance
8. **LANGTEST_COG** (Langue du test) - Essentiel analyses multilingues
9. **MATHEASE** (Math easier than other subjects) - Perception pertinente
10. **MISSSC** (Missing school >3 months) - Impact Ã©ducatif significatif
11. **IC184** (Usage TIC mathÃ©matiques) - Pertinent direct pour MathScore
12. **METASPAM** (MÃ©tacognition) - Important selon littÃ©rature
13. **COMPETE** (CompÃ©tition) - SpÃ©cifique aux maths

---

## âš ï¸ POINTS CRITIQUES Ã€ NE PAS OUBLIER

### âŒ NE JAMAIS

1. Inclure les PValues dans les features
2. Appliquer transformations (scaling, encoding) AVANT le split train/test
3. Utiliser les donnÃ©es de test pour fit des transformateurs
4. Supprimer des variables sans validation de leur faible importance
5. Ignorer les >60% de features avec >50% de missing values

### âœ… TOUJOURS

1. Splitter AVANT tout preprocessing
2. Fixer random_state pour reproductibilitÃ©
3. PrÃ©server l'information ordinale quand elle existe
4. Valider avec cross-validation pour Ã©viter surapprentissage
5. Tester performance sur test set final UNE SEULE FOIS

---

## ğŸ’¡ INSIGHTS MAJEURS

### 1. Impact DisproportionnÃ© des Variables CatÃ©gorielles
- **3 variables ISCO gÃ©nÃ¨rent 97% des features** aprÃ¨s one-hot encoding
- Le regroupement ISCO est l'optimisation la plus impactante du preprocessing
- RÃ©duction de ~1910 â†’ ~50 features avec regroupement intelligent

### 2. OpportunitÃ© Exceptionnelle de RÃ©duction
- **40% des variables catÃ©gorielles sont des mÃ©tadonnÃ©es** sans valeur prÃ©dictive
- Suppression avec risque ZÃ‰RO identifiÃ©e pour 10 variables (mÃ©tadonnÃ©es)
- 5 redondances ordinales + 7 redondances catÃ©gorielles supplÃ©mentaires
- **ROI maximal** : Variables catÃ©gorielles offrent le plus grand gain avec risque minimal

### 3. Validation Scientifique
- Recommandations alignÃ©es avec 4 Ã©tudes scientifiques analysÃ©es
- Variables critiques (ESCS, HISEI, ICTRES) systÃ©matiquement importantes
- Pipeline KNN imputation + StandardScaler + RFE validÃ© empiriquement

### 4. Trade-off DimensionnalitÃ© vs Information
- **ScÃ©nario conservateur** : -89% features avec perte information minimale
- Variables ordinales : -7 variables (-7.3% : -5 suppressions + -2 scores composites)
- Variables catÃ©gorielles : -17 variables (-24.3% : -10 mÃ©tadonnÃ©es + -7 redondances)
- Impact massif sur features grÃ¢ce au regroupement ISCO (620 â†’ 10 catÃ©gories)

---

## ğŸ¯ RECOMMANDATION FINALE

### Action ImmÃ©diate (Cette Semaine)

**ImplÃ©menter ScÃ©nario CONSERVATEUR (Phases 1-2)** :

âœ… **Phase 1** : Supprimer 22 variables (mÃ©tadonnÃ©es et redondances)
âœ… **Phase 2** : Regrouper ISCO + crÃ©er 2 scores composites

**RÃ©sultat attendu** :
- Variables : 166 â†’ 142 (-14.5%)
- Features : ~2093 â†’ ~224 (-89%)
- Risque : MINIMAL
- Timeline : IMMÃ‰DIAT

### Validation Empirique (Semaine Prochaine)

ğŸ“Š Tester corrÃ©lations variables "Ã  Ã©valuer" (COVID, TIC)
ğŸ§ª Comparer performance modÃ¨le avant/aprÃ¨s rÃ©duction
ğŸ“ˆ Mesurer impact sur RÂ² et RMSE

### DÃ©cision Phase 3 (Selon RÃ©sultats Validation)

Si tests confirment faible importance :
- Consolider/supprimer 7 variables COVID
- Consolider 4 variables TIC redondantes
- **Gain supplÃ©mentaire potentiel** : -8 Ã  -11 variables

---

## ğŸ“Š IMPACT GLOBAL ATTENDU

### Transformation du Dataset

**AVANT Preprocessing** :
```
Total features brutes estimÃ©es:
- NumÃ©riques: 81 features
- Ordinales: ~96 features
- CatÃ©gorielles: ~1910 features (one-hot)
- Groupement: 6 features
TOTAL: ~2093 features
```

**APRÃˆS Preprocessing Conservateur** :
```
Total features optimisÃ©es:
- NumÃ©riques: 81 features
- Ordinales: ~87 features (-9)
- CatÃ©gorielles: ~50 features (-1860!)
- Groupement: 6 features
TOTAL: ~224 features
```

### ğŸ‰ GAIN GLOBAL : -89% de features (-1869 features)

### BÃ©nÃ©fices Attendus

âœ… **RÃ©duction temps de calcul** : ~80-90% sur training et inference
âœ… **Diminution risque overfitting** : Curse of dimensionality Ã©vitÃ©e
âœ… **AmÃ©lioration gÃ©nÃ©ralisation** : ModÃ¨le plus robuste
âœ… **Meilleure interprÃ©tabilitÃ©** : Focus sur variables Ã  haute valeur
âœ… **Facilitation feature engineering** : Base saine pour itÃ©rations

---
