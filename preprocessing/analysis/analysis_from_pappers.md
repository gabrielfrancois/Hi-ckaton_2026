Je vais analyser les articles scientifiques de la base de connaissance pour identifier les meilleures pratiques de preprocessing pour pr√©dire le score PISA.Bas√© sur l'analyse des articles scientifiques de la base de connaissance, voici mes **recommandations synth√©tiques pour le preprocessing des donn√©es PISA** :

## üìä SYNTH√àSE DES RECOMMANDATIONS

### 1. **GESTION DES VALEURS MANQUANTES** 

**Quoi faire :**
- **Imputation KNN (k=5)** pour les variables continues et ordinales (recommand√© par 2 √©tudes)
- **Mode/valeur la plus fr√©quente** pour les variables cat√©gorielles
- **√âliminer les variables** avec >50% de valeurs manquantes

**Pourquoi :**
- KNN pr√©serve mieux les relations entre variables que l'imputation simple
- √âvite d'introduire du bruit avec des features artificiellement remplies
- Les variables avec >50% de missing n'apportent pas d'information fiable

### 2. **PROTECTION CONTRE LE DATA LEAKAGE**

**Quoi faire :**
- **EXCLURE ABSOLUMENT** tous les PValues (PV1MATH √† PV10MATH, etc.)
- Exclure les variables WLE (Weighted Likelihood Estimates)
- Ne conserver qu'UN seul score moyen par domaine si n√©cessaire

**Pourquoi :**
- Les PValues sont g√©n√©r√©s par imputation multiple et repr√©sentent d√©j√† la cible
- Les inclure donne une pr√©cision artificiellement √©lev√©e mais inutilisable
- Risque de fuite d'information entre train/test

### 3. **NORMALISATION ET STANDARDISATION**

**Quoi faire :**
- **Min-Max Scaling [0,1]** pour les algorithmes sensibles √† la magnitude (SVM, r√©seaux de neurones)
- **StandardScaler (mean=0, std=1)** pour les variables continues avant mod√©lisation
- Appliquer apr√®s le split train/test pour √©viter le data leakage

**Pourquoi :**
- Am√©liore la convergence des mod√®les
- Met toutes les features sur une √©chelle comparable
- Essentiel pour l'interpr√©tabilit√© des coefficients

### 4. **ENCODAGE DES VARIABLES**

**Quoi faire :**
- **One-hot encoding** pour les variables cat√©gorielles nominales
- **Ordinal encoding (rangs entiers)** pour les variables ordinales (ex: nombre de livres √† la maison)
- **Variables binaires** en 0/1

**Pourquoi :**
- One-hot √©vite d'imposer un ordre artificiel sur les cat√©gories nominales
- L'ordinal encoding pr√©serve l'information d'ordre naturel
- Compatible avec tous les algorithmes ML

### 5. **S√âLECTION DE FEATURES**

**Quoi faire :**
- **Approche hybride** : Recursive Feature Elimination (RFE) + Mutual Information (MI)
- **Permutation Importance** apr√®s mod√©lisation pour identifier les top features
- Utiliser **SHAP values** pour l'analyse d'importance
- Conserver ~20-35 features optimales selon les analyses

**Pourquoi :**
- RFE √©limine it√©rativement les features peu importantes
- MI capture les d√©pendances non-lin√©aires
- SHAP fournit une interpr√©tabilit√© locale et globale
- R√©duit le surapprentissage et am√©liore la g√©n√©ralisation

### 6. **GESTION DE LA DIMENSIONNALIT√â**

**Quoi faire :**
- Envisager **UMAP** pour visualisation (pas n√©cessairement pour mod√©lisation)
- Filtrer les features bas√© sur l'importance permut√©e
- √âliminer les variables redondantes (multicolin√©arit√©)

**Pourquoi :**
- 308 variables ‚Üí trop de dimensions, risque de curse of dimensionality
- Les mod√®les tree-based g√®rent bien la multicolin√©arit√©, mais pas les mod√®les lin√©aires
- La r√©duction dimensionnelle am√©liore l'efficacit√© computationnelle

### 7. **TRAITEMENT DES VALEURS EXTR√äMES**

**Quoi faire :**
- **Winsorization** au 99√®me percentile pour les variables continues (ex: temps d'√©tude)
- Identifier et traiter les valeurs aberrantes irr√©alistes

**Pourquoi :**
- Certains √©l√®ves reportent des valeurs irr√©alistes
- Limite l'influence excessive des outliers

### 8. **SPLIT DES DONN√âES**

**Quoi faire :**
- **60% train / 20% validation / 20% test** (standard)
- **Stratified K-Fold Cross-Validation** (k=5) avec undersampling si d√©s√©quilibre
- Fixer un random seed pour la reproductibilit√©

**Pourquoi :**
- Garantit des proportions √©quilibr√©es dans chaque fold
- Le validation set permet le tuning sans toucher au test set
- La reproductibilit√© est essentielle pour la recherche

### 9. **VARIABLES PRIORITAIRES IDENTIFI√âES**

**Les plus importantes selon les √©tudes :**
- **ESCS** (statut socio-√©conomique et culturel) - syst√©matiquement important
- **HISEI** (statut occupationnel parental) - syst√©matiquement important
- **ICTRES** (acc√®s aux technologies) - tr√®s important pour tous domaines
- **METASPAM** (m√©tacognition) - important
- **CPERWEEK** (heures d'enseignement) - important
- **COMPETE** (comp√©tition) - sp√©cifique aux maths

## ‚ö†Ô∏è POINTS CRITIQUES

1. **NE JAMAIS** inclure les PValues dans les features
2. **TOUJOURS** appliquer les transformations (scaling, encoding) APR√àS le split
3. **G√âRER** les >60% de features avec >50% de missing values
4. **PR√âSERVER** l'information ordinale quand elle existe
5. **VALIDER** que les mod√®les ne sur-apprennent pas avec validation crois√©e

## üéØ PIPELINE RECOMMAND√â

```
1. Analyser le % de missing par variable
2. √âliminer PValues et WLE
3. √âliminer features avec >50% missing
4. Split train/validation/test (60/20/20)
5. Imputation KNN sur train, appliquer sur validation/test
6. Winsorization des outliers
7. Encoding (one-hot pour cat√©gorielles, ordinal pour ordinales)
8. Standardisation/normalisation
9. Feature selection (RFE + MI)
10. Mod√©lisation avec cross-validation
11. Analyse importance (Permutation + SHAP)
```

Cette approche est valid√©e par les 4 √©tudes analys√©es et adapt√©e √† ton contexte sp√©cifique PISA.